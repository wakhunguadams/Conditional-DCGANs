{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SOTA Projected GAN for Prostate Cancer Biopsy Image Synthesis\n",
    "\n",
    "This notebook implements a high-fidelity **Projected GAN** for synthesizing prostate biopsy patches conditioned on ISUP grade (0-5).\n",
    "\n",
    "## Key Innovations\n",
    "- **Style-Modulated Generator**: Uses AdaIN layers to inject class styles into a constant starting tensor.\n",
    "- **Projected Discriminator**: Leverages a pre-trained EfficientNet-B0 backbone to extract multi-resolution features.\n",
    "- **Projection Discrimination**: Directly matches feature vectors with class label embeddings for accurate conditioning.\n",
    "- **Diversity Loss (LZ)**: Maximizes visual variety between different noise vectors to prevent mode collapse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from torchvision.models import efficientnet_b0\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaIN(nn.Module):\n",
    "    def __init__(self, style_dim, num_features):\n",
    "        super().__init__()\n",
    "        self.norm = nn.InstanceNorm2d(num_features)\n",
    "        self.fc = nn.Linear(style_dim, num_features * 2)\n",
    "    def forward(self, x, style):\n",
    "        style = self.fc(style).unsqueeze(2).unsqueeze(3)\n",
    "        gamma, beta = style.chunk(2, 1)\n",
    "        return self.norm(x) * (1 + gamma) + beta\n",
    "\n",
    "class SynthesisBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, style_dim, upsample=True):\n",
    "        super().__init__()\n",
    "        self.upsample = upsample\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, 1, 1, bias=False)\n",
    "        self.adain1 = AdaIN(style_dim, out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False)\n",
    "        self.adain2 = AdaIN(style_dim, out_channels)\n",
    "    def forward(self, x, style):\n",
    "        if self.upsample:\n",
    "            x = F.interpolate(x, scale_factor=2, mode='bilinear', align_corners=False)\n",
    "        x = F.leaky_relu(self.adain1(self.conv1(x), style), 0.2)\n",
    "        x = F.leaky_relu(self.adain2(self.conv2(x), style), 0.2)\n",
    "        return x\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, nz=512, style_dim=512, n_classes=6, ngf=64):\n",
    "        super().__init__()\n",
    "        self.label_emb = nn.Embedding(n_classes, 128)\n",
    "        self.mapping = nn.Sequential(\n",
    "            nn.Linear(nz + 128, style_dim), nn.LeakyReLU(0.2),\n",
    "            nn.Linear(style_dim, style_dim)\n",
    "        )\n",
    "        self.const = nn.Parameter(torch.randn(1, ngf*16, 4, 4))\n",
    "        self.blocks = nn.ModuleList([\n",
    "            SynthesisBlock(ngf*16, ngf*8, style_dim), # 8x8\n",
    "            SynthesisBlock(ngf*8, ngf*4, style_dim),  # 16x16\n",
    "            SynthesisBlock(ngf*4, ngf*2, style_dim),  # 32x32\n",
    "            SynthesisBlock(ngf*2, ngf*2, style_dim),  # 64x64\n",
    "            SynthesisBlock(ngf*2, ngf, style_dim),    # 128x128\n",
    "            SynthesisBlock(ngf, ngf, style_dim)       # 256x256\n",
    "        ])\n",
    "        self.to_rgb = nn.Sequential(nn.Conv2d(ngf, 3, 1), nn.Tanh())\n",
    "    def forward(self, z, labels):\n",
    "        styles = self.mapping(torch.cat([z, self.label_emb(labels)], 1))\n",
    "        x = self.const.repeat(z.size(0), 1, 1, 1)\n",
    "        for block in self.blocks: x = block(x, styles)\n",
    "        return self.to_rgb(x)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, n_classes=6):\n",
    "        super().__init__()\n",
    "        backbone = efficientnet_b0(pretrained=True).features\n",
    "        self.features = nn.ModuleList([backbone[i] for i in range(len(backbone))])\n",
    "        for p in self.parameters(): p.requires_grad = False\n",
    "        self.heads = nn.ModuleList([\n",
    "            nn.Sequential(nn.Conv2d(24, 1, 3, padding=1)),\n",
    "            nn.Sequential(nn.Conv2d(40, 1, 3, padding=1)),\n",
    "            nn.Sequential(nn.Conv2d(112, 1, 3, padding=1)),\n",
    "            nn.Sequential(nn.Conv2d(320, 1, 3, padding=1))\n",
    "        ])\n",
    "        self.proj = nn.Conv2d(320, 512, 1)\n",
    "        self.cls_emb = nn.Embedding(n_classes, 512)\n",
    "    def forward(self, x, labels):\n",
    "        feats = []\n",
    "        for i, layer in enumerate(self.features):\n",
    "            x = layer(x)\n",
    "            if i in [2, 3, 5, 7]: feats.append(x)\n",
    "        score = sum([h(f).mean(dim=[2,3]) for h, f in zip(self.heads, feats)]) / 4\n",
    "        proj_score = (self.proj(feats[-1]).mean(dim=[2,3]) * self.cls_emb(labels)).sum(dim=1, keepdim=True)\n",
    "        return score + proj_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    batch_size = 16\n",
    "    lr = 0.0001\n",
    "    nz = 512\n",
    "    epochs = 300\n",
    "    data_dir = './panda_data/patches_256'\n",
    "\n",
    "config = Config()\n",
    "G = Generator().to(device)\n",
    "D = Discriminator().to(device)\n",
    "opt_G = optim.Adam(G.parameters(), lr=config.lr, betas=(0.0, 0.99))\n",
    "opt_D = optim.Adam(D.parameters(), lr=config.lr*4, betas=(0.0, 0.99))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Step with Diversity Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(real_imgs, labels):\n",
    "    real_imgs, labels = real_imgs.to(device), labels.to(device)\n",
    "    bs = real_imgs.size(0)\n",
    "\n",
    "    # Train D\n",
    "    opt_D.zero_grad()\n",
    "    d_real = D(real_imgs, labels)\n",
    "    z = torch.randn(bs, config.nz, device=device)\n",
    "    fake = G(z, labels)\n",
    "    d_fake = D(fake.detach(), labels)\n",
    "    loss_D = torch.mean(F.relu(1.0 - d_real)) + torch.mean(F.relu(1.0 + d_fake))\n",
    "    loss_D.backward()\n",
    "    opt_D.step()\n",
    "\n",
    "    # Train G\n",
    "    opt_G.zero_grad()\n",
    "    z1, z2 = torch.randn(bs, config.nz, device=device), torch.randn(bs, config.nz, device=device)\n",
    "    f1, f2 = G(z1, labels), G(z2, labels)\n",
    "    loss_G_adv = -torch.mean(D(f1, labels))\n",
    "    # Diversity Loss (LZ)\n",
    "    loss_G_lz = torch.mean(torch.abs(z1 - z2)) / (torch.mean(torch.abs(f1 - f2)) + 1e-8)\n",
    "    loss_G = loss_G_adv + (loss_G_lz * 0.1)\n",
    "    loss_G.backward()\n",
    "    opt_G.step()\n",
    "    return loss_D.item(), loss_G.item()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
